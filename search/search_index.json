{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About this guide","text":"<p>This guide is a work in progress</p> <p>This guide is a work in progress. Not all content is complete, and some sections may be missing.</p>"},{"location":"#for-who-is-it","title":"For who is it?","text":"<p>This guide is intended for software engineers of all experience levels. Beginners will find it helpful for learning best practices and becoming familiar with many types of tests. More experienced developers can use it to refresh and organize their knowledge. </p> <p>The example code is written in JVM languages such as Java, with tests using JUnit or Spock, but most of the concepts are universal and can be applied to any programming language or testing framework. Additionally, the code examples are mostly written in a hexagonal architecture style (see \"example\" module on GitHub).</p>"},{"location":"#goals","title":"Goals","text":"<p>This guide has a few goals:</p> <ul> <li>To unify the terminology and understanding of different test types. In the software industry, test names are often used inconsistently \u2014 for example, what exactly is a unit test? What distinguishes a unit test from an integration, module, or component test?</li> <li>To demonstrate how to cover more scenarios with fewer tests, making them easier to maintain and understand.</li> <li>To introduce lesser-known but valuable types of tests, such as mutation tests or architectural tests.</li> <li>To show why commonly accepted practices, like writing a unit test for every class, may not always be the best approach for your project.</li> <li>To explain the importance of a healthy test pyramid and provide guidance on how to achieve it.</li> </ul>"},{"location":"#feedback-and-contribution","title":"Feedback and Contribution","text":"<p>Your feedback is invaluable for improving this guide. If you notice any mistakes, unclear explanations, or areas that could be expanded, please create an issue in the GitHub repository for this guide. Contributions of all kinds\u2014such as corrections, suggestions, or additional examples\u2014are warmly welcomed.</p>"},{"location":"avoid/","title":"What should be avoided","text":""},{"location":"avoid/#waiting-in-tests","title":"Waiting in tests","text":"<p>Since tests should be fast and efficient, avoid using blocking calls like <code>sleep</code> in your test code. Using <code>Thread.sleep</code> introduces unnecessary delays and can lead to flaky tests.</p> <p>For example, instead of writing:</p> <pre><code>Thread.sleep(1000);\n</code></pre> <p>It's preferable to use a more robust waiting mechanism. One such alternative is provided by Awaitility, which allows you to wait for a condition to be met within a specified timeout:</p> <pre><code>await()\n    .atMost(1,SECONDS)\n    .until(() -&gt;{\n        // some condition\n        });\n</code></pre>"},{"location":"avoid/#avoid-using-verify-unless-absolutely-necessary","title":"Avoid using <code>verify</code> unless absolutely necessary","text":"<p>Using <code>verify</code> in your tests can lead to brittle tests that are tightly coupled to the implementation details of the code being tested. This makes your tests less maintainable and more likely to break with minor changes in the implementation.</p> <p>Let\u2019s consider the following example:</p> <pre><code>// given\nUser user = createExpectedUser();\n\nwhen(createUserFactory.createUser(\"login\", \"password\"))\n        .thenReturn(user);\n\n// when\nUser createdUser = createUserService.createUser(createCreateUserCommand());\n\n// then\nverify(createUserFactory).createUser(any()); // this line is not needed\n\nassertCreatedUser(createdUser);\n</code></pre> <p>In this example, verifying that <code>createUserFactory</code> was called is not necessary. If the <code>createUserFactory.createUser</code> method is not called, the test will fail due to the <code>assertCreatedUser</code> check. From the test\u2019s perspective, it doesn\u2019t matter whether the method was called or not\u2014the test should focus on the observable behavior of the system under test, not on the internal implementation details or interactions with dependencies.</p>"},{"location":"avoid/#avoid-if-logic-in-test-code","title":"Avoid <code>if</code> logic in test code","text":"<p>Using <code>if</code> statements in your test code can lead to complex and hard-to-read tests. Tests should always be straightforward and easy to understand, focusing exclusively on the behavior of the code under test.</p> <p>Here\u2019s an example of a test containing <code>if</code> logic:</p> <pre><code>@ParameterizedTest\n@EnumSource(UserType.class)\nvoid shouldGetUserPermissions(UserType type) {\n    // given\n    User user = createUser(type);\n\n    // when\n    Permissions permissions = useCase.getPermissions(user);\n\n    // then\n    if (UserType.ADMIN.equals(type)) {\n        assertHasWritePermissions(permissions);\n    } else {\n        assertHasReadOnlyPermissions(permissions);\n    }\n}\n\nprivate static User createUser(UserType type) {\n    return switch (type) {\n        case ADMIN -&gt; createAdminUser();\n        case MODERATOR -&gt; createModeratorUser();\n        // ... other cases\n    };\n}\n</code></pre> <p>In most cases, the presence of <code>if</code> logic in tests indicates a poor use of parameterized tests. In this example, the test could be simplified and made more readable by using separate test methods for each <code>UserType</code>:</p> <pre><code>@Test\nvoid shouldAdministratorHaveWritePermission() {\n    // given\n    User user = createUser(UserType.ADMIN);\n\n    // when\n    Permissions permissions = useCase.getPermissions(user);\n\n    // then\n    assertHasWritePermissions(permissions);\n}\n\n@Test\nvoid shouldUserHaveReadOnlyPermission() {\n    // given\n    User user = createUser(UserType.MODERATOR);\n\n    // when\n    Permissions permissions = useCase.getPermissions(user);\n\n    // then\n    assertHasReadOnlyPermissions(permissions);\n}\n</code></pre>"},{"location":"avoid/#avoid-using-any-or-wildcard-matchers-in-tests","title":"Avoid using any or wildcard matchers in tests","text":"<p>Mocking libraries like Mockito allow you to use <code>any()</code> to match arguments, but this can create overly broad tests that fail to verify specific behavior.</p> <p>Consider this code:</p> <pre><code>public UserIdentifier create(Command command) {\n    User user = userFactory.create(command.firstName(), command.lastName());\n    insertUserPort.insert(user);\n\n    return user.identifier();\n}\n</code></pre> <p>and the corresponding test with Spock equivalent to Mockito's <code>any()</code>:</p> <pre><code>def \"Should create user\"() {\n    given: \"Command of user creation\"\n    def command = new CreateUserUseCase.Command(FIRST_NAME, LAST_NAME)\n\n    this.userFactory.create(_ as String, _ as String) &gt;&gt; new User(new UserIdentifier(GENERATED_IDENTIFIER), FIRST_NAME, LAST_NAME)\n\n    when: \"User is created\"\n    def identifier = createUserUseCase.create(command)\n\n    // rest of test ommitted\n}\n</code></pre> <p>In this test, using <code>_ as String</code> (which is equivalent to <code>any()</code> in Mockito) does not verify that the correct values are passed to the <code>create</code> method of <code>userFactory</code>. This can lead to false positives, where the test passes even if the method is called with incorrect arguments. It is better to verify that specific values are provided as arguments.</p> <pre><code>this.userFactory.create(FIRST_NAME LAST_NAME) &gt;&gt; new User(new UserIdentifier(GENERATED_IDENTIFIER), FIRST_NAME, LAST_NAME)\n</code></pre>"},{"location":"avoid/#avoid-using-lenient-mocks","title":"Avoid using lenient mocks","text":"<p>Lenient mocks can negatively impact the maintainability of tests. They allow unused mocks or unnecessary stubbing to remain in the test suite, making it difficult to understand which mocks are actually required. In many tests that use lenient mocks, I have seen numerous mocks, many of which were needed in the past but are no longer relevant. This leads to confusion and makes it harder to determine the true purpose of the test.</p> <p>Example: <pre><code>    @Mock\n    private UserFactory userFactory;\n\n    @Mock\n    private InsertUserPort insertUserPort;\n\n    @Mock\n    private DependentClassThatThisServiceIsNotLongerUse dependentClass;\n\n    @InjectMocks\n    private CreateUserService createUserService;\n\n    @BeforeEach\n    void setUp() {\n        lenient().when(dependentClass.doSomething()).thenReturn(1);\n    }\n\n    @Test\n    void shouldCreateUser() {\n        // Given\n        CreateUserUseCase.Command command = new CreateUserUseCase.Command(FIRST_NAME, LAST_NAME);\n\n        when(userFactory.create(command)).thenReturn(\n            new User(new UserIdentifier(GENERATED_IDENTIFIER), FIRST_NAME, LAST_NAME));\n\n        // When\n        createUserService.create(command);\n\n        // Then\n        var captor = ArgumentCaptor.forClass(User.class);\n\n        verify(insertUserPort).insert(captor.capture());\n        // assertions for created user omitted\n    }\n</code></pre></p> <p>In this example, <code>DependentClassThatThisServiceNoLongerUses</code> is no longer used by the class under test, but the mock and its lenient stubbing remain in the test. This can be confusing and obscures the real purpose of the test. Lenient mocks often lead to an excess of unused or irrelevant mocks. If you remove the <code>lenient</code> configuration, the test will fail, sending a clear signal that this mock or stubbing should be removed.</p> <pre><code>Unnecessary stubbings detected.\nClean &amp; maintainable test code requires zero unnecessary code.\nFollowing stubbings are unnecessary (click to navigate to relevant line of code):\n  1. -&gt; at pl.sejdii.example.user.application.service.MockitoAntiPatternExampleTest.setUp(MockitoAntiPatternExampleTest.java:40)\n</code></pre> <p>In Spock, the situation is different: all mocks are lenient by default. However, you can enforce strictness in your tests by specifying <code>0 * _</code> interactions. Since leniency is a design feature of Spock, it is generally accepted as part of the framework, and it is not recommended to use <code>0 * _</code> in every test.</p>"},{"location":"integration/integration_tests/","title":"Integration Tests","text":""},{"location":"integration/integration_tests/#main-goal","title":"Main goal","text":"<p>The primary goal of integration testing is to verify how an application interacts with external systems.  For example, is the REST controller properly configured? Does the Kafka listener work as expected? Are the SQL  queries executed correctly? Integration tests for both incoming and outgoing adapters help provide answers  to these questions.</p>"},{"location":"integration/integration_tests/#main-concepts","title":"Main concepts","text":""},{"location":"integration/integration_tests/#test-slices","title":"Test Slices","text":"<p>As integration tests only verify the incoming and outgoing adapters, we don't need to start the entire application  context\u2014only the classes and configurations required for specific tests. This approach speeds up test execution.  The Spring Boot framework provides multiple test slice annotations to help achieve this.  All available test slices can be found in the documentation.</p>"},{"location":"integration/integration_tests/#outgoing-adapters","title":"Outgoing adapters","text":""},{"location":"integration/integration_tests/#database-adapters","title":"Database adapters","text":"<p>Integration tests for database adapters allow us to verify:</p> <ul> <li>If custom queries are correctly constructed and return the expected results.</li> <li>The accuracy of the Hibernate model and its mappings.</li> <li>The correctness of database migrations (for example, those performed using Flyway).</li> </ul> <p>It is important to run these tests using the same type of database as is used in production.  This can be easily achieved with the help of the Testcontainers library,  which allows spinning up a real database instance (such as PostgreSQL) in a Docker container during test execution.</p> <p>Why not with in-memory db like H2?</p> <p>While it may be tempting to use an in-memory database like H2 for tests because it is easy to set up,  this approach can lead to issues as the project grows. Eventually, you may need to use features that are available  in your production database but not supported by H2. This can result in inconsistent behavior and the need to add  workarounds or separate migrations just for test purposes. Such incompatibilities can lead to tests passing locally  but failing in production. In contrast, Testcontainers are also straightforward to configure and run quickly,  eliminating the need for H2.  </p> <p>However, in-memory databases can be a good option during the early stages of a project when the choice of a  production database has not yet been finalized and you want to delay this decision.</p> <p>Below is an example of an integration test for a database adapter. This test checks whether an entity is correctly  inserted into the database. The test runs against a real PostgreSQL instance provided by Testcontainers.</p> <pre><code>class ParticipantPostgresAdapterTestIT extends PostgresTestIT {\n\n    @Autowired private ReservationParticipantRepository repository;\n\n    private ParticipantPostgresAdapter adapter;\n\n    @BeforeEach\n    void setup() {\n        adapter = new ParticipantPostgresAdapter(repository);\n    }\n\n    @Test\n    void shouldInsertParticipant() {\n        // given\n        ReservationParticipant participant = ReservationParticipantTestFactory.create();\n\n        // when\n        adapter.insert(participant);\n\n        // then\n        StatisticAssertions.assertThat(statistics).hasQueryCount(1).hasInsertCount(1);\n\n        ReservationParticipantEntity savedParticipant =\n                repository.findByIdentifier(IDENTIFIER).orElseThrow();\n        assertThat(savedParticipant.getFirstName()).isEqualTo(FIRST_NAME);\n        assertThat(savedParticipant.getSurname()).isEqualTo(SURNAME);\n    }\n}\n</code></pre> <p>And <code>PostgresTestIT</code> which is a template from postgres database adapters tests.</p> <pre><code>@DataJpaTest\n@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE)\nabstract class PostgresTestIT {\n\n    protected static final PostgreSQLContainer&lt;?&gt; postgreSQLContainer =\n            new PostgreSQLContainer&lt;&gt;(DockerImageName.parse(\"postgres:latest\"));\n\n    static {\n        postgreSQLContainer.start();\n    }\n\n    @DynamicPropertySource\n    static void registerProperties(DynamicPropertyRegistry registry) {\n        registry.add(\"spring.datasource.url\", postgreSQLContainer::getJdbcUrl);\n        registry.add(\"spring.datasource.username\", postgreSQLContainer::getUsername);\n        registry.add(\"spring.datasource.password\", postgreSQLContainer::getPassword);\n    }\n\n    @Autowired private SessionFactory sessionFactory;\n\n    protected Statistics statistics;\n\n    @BeforeEach\n    void enableStatistics() {\n        statistics = sessionFactory.getStatistics();\n        statistics.clear();\n        statistics.setStatisticsEnabled(true);\n    }\n}\n</code></pre> <p>This test also verifies Hibernate statistics to ensure that the entity is mapped and managed efficiently.  Monitoring these statistics helps detect issues such as the N+1 query problem or other problems related to Hibernate entity configuration.</p> <p>Why data are not cleaned up after the test?</p> <p>Since <code>@DataJpaTest</code> ensures that the entire test runs within a single transaction, all changes made during  the test are rolled back after the test completes. Therefore, manual cleanup is not necessary.</p> <p>However, in some cases, this behavior of <code>@DataJpaTest</code> may not be desirable. To disable transactional behavior  for a specific test, you can use the annotation <code>@Transactional(propagation = Propagation.NOT_SUPPORTED)</code> to  suspend the transaction created by the <code>@DataJpaTest</code> annotation.</p>"},{"location":"integration/integration_tests/#amqp-adapters","title":"AMQP adapters","text":"<p>Integration tests for AMQP adapters ensure that messages are correctly sent to message brokers, such as Kafka or RabbitMQ.</p> <p>Is it worth performing such tests?</p> <p>If the message-sending logic is straightforward, these integration tests can often be omitted; verification is then  typically covered with module tests. However, if the logic includes more complex scenarios or multiple conditions, integration  tests become valuable to ensure that the adapter interacts with the broker as intended.</p> <p>Integration testing of a Kafka-based AMQP adapter is exemplified below:</p> <pre><code>class SendMessageKafkaAdapterTestIT extends KafkaTestIT {\n\n    private SendMessageKafkaAdapter adapter;\n\n    @BeforeEach\n    void setup() {\n        adapter = new SendMessageKafkaAdapter(template, objectMapper);\n    }\n\n    @Test\n    void shouldSendMessage(EmbeddedKafkaBroker embeddedKafkaBroker) {\n        // given\n        Room room = new Room(new RoomIdentifier(\"178caccd-d9cd-4e35-886d-2fc6e19f8ed5\"), 5);\n        Reservation reservation = createReservation(room);\n        room.reserve(reservation);\n\n        // when\n        adapter.send(room, reservation);\n\n        // then\n        String messageContent = getMessageFromTopic(embeddedKafkaBroker, \"roomReserved\");\n        JsonAssert.comparator(JsonCompareMode.STRICT)\n                .assertIsMatch(\n                        \"\"\"\n                                {\n                                    \"roomIdentifier\":\"178caccd-d9cd-4e35-886d-2fc6e19f8ed5\",\n                                    \"reservationIdentifier\":\"14c9caff-cdae-46b9-9448-86fa2ee7bfd1\",\n                                    \"startTime\":[2025,6,23,10,0],\n                                    \"endTime\":[2025,6,23,12,0]\n                                }\n                                \"\"\",\n                        messageContent);\n    }\n}\n</code></pre> <p>abstract base class for Kafka Integration tests:</p> <pre><code>@EmbeddedKafka(kraft = true)\nabstract class KafkaTestIT {\n\n  protected final ObjectMapper objectMapper = createObjectMapper();\n\n  private final KafkaConfiguration kafkaConfiguration = new KafkaConfiguration();\n\n  protected KafkaTemplate&lt;String, String&gt; template;\n\n  @BeforeEach\n  void prepareKafkaTemplate(EmbeddedKafkaBroker embeddedKafkaBroker) {\n    embeddedKafkaBroker.addTopics(kafkaConfiguration.roomReservedTopic());\n\n    Map&lt;String, Object&gt; producerProps = KafkaTestUtils.producerProps(embeddedKafkaBroker);\n    ProducerFactory&lt;String, String&gt; producerFactory =\n        new DefaultKafkaProducerFactory&lt;&gt;(producerProps);\n    template = new KafkaTemplate&lt;&gt;(producerFactory);\n  }\n\n  protected String getMessageFromTopic(EmbeddedKafkaBroker embeddedKafkaBroker, String topic) {\n    Map&lt;String, Object&gt; consumerProps =\n        KafkaTestUtils.consumerProps(\"testT\", \"false\", embeddedKafkaBroker);\n    DefaultKafkaConsumerFactory&lt;String, String&gt; cf =\n        new DefaultKafkaConsumerFactory&lt;&gt;(consumerProps);\n    Consumer&lt;String, String&gt; consumer = cf.createConsumer();\n    embeddedKafkaBroker.consumeFromAnEmbeddedTopic(consumer, topic);\n\n    return KafkaTestUtils.getSingleRecord(consumer, topic).value();\n  }\n\n  private static ObjectMapper createObjectMapper() {\n    ObjectMapper objectMapper = new ObjectMapper();\n    objectMapper.registerModule(new JavaTimeModule());\n    objectMapper.registerModule(new Jdk8Module());\n    return objectMapper;\n  }\n}\n</code></pre> <p>This test uses the <code>@EmbeddedKafka</code> annotation provided by Spring Boot (documentation). This approach is suitable for verifying message publication without requiring access to a real broker.</p> <p>Considerations:</p> <ul> <li>Configuration Duplication - One drawback to using <code>@EmbeddedKafka</code> is the requirement to manually configure topics      and Kafka-related beans in the test context. The test environment does not automatically inherit configuration from the production code.</li> <li>Alternative: Testcontainers - As an alternative to <code>@EmbeddedKafka</code>, Testcontainers      may be used to spin up a real Kafka broker in a Docker container. This approach more closely replicates      production conditions.</li> <li>Test Scope: - When leveraging Testcontainers, there is a choice between starting the entire Spring context      (which may negatively impact test performance) and initializing only the necessary beans or configurations required      for AMQP integration testing.</li> </ul>"},{"location":"integration/integration_tests/#incoming-adapters","title":"Incoming Adapters","text":""},{"location":"integration/integration_tests/#web-adapters","title":"Web Adapters","text":"<p>The goal of the incoming web adapters integration test is to check:</p> <ul> <li>Endpoint Configuration: Verify that endpoints are correctly mapped and accessible at the intended URLs.</li> <li>Request/Response Handling: Ensure that the controller accurately interprets incoming requests and that responses    have the correct status codes, headers, and body content.</li> <li>Validation and Error Handling: Check that invalid input triggers appropriate error responses.</li> <li>Authorization (if applicable): Confirm that secured endpoints enforce proper authentication and authorization    rules.</li> </ul> <p>Example of a test:</p> <pre><code>@WebMvcTest\nclass ReserveRoomRestControllerTest {\n\n    private static final ReservationIdentifier RESERVATION_IDENTIFIER =\n            new ReservationIdentifier(\"a674fc0c-0d74-469d-beaa-266dd98b921c\");\n    private static final String ROOM_IDENTIFIER = \"0fd6c5e5-ff2c-4b7a-aa06-2a6581d0fe9b\";\n\n    @Autowired\n    private MockMvc mockMvc;\n\n    @MockitoBean\n    private ReserveRoomUseCase useCase;\n\n    @Test\n    void shouldReserveRoom() throws Exception {\n        // given\n        given(\n                useCase.reserve(\n                        assertArg(\n                                command -&gt; {\n                                    assertThat(command.reservationOwnerIdentifier().value())\n                                            .isEqualTo(ReservationParticipantTestFactory.IDENTIFIER_AS_STRING);\n                                    assertThat(command.roomIdentifier().value()).isEqualTo(ROOM_IDENTIFIER);\n                                    assertThat(command.period()).isEqualTo(createPeriodBetween(11, 15));\n                                    assertThat(command.numberOfParticipants()).isEqualTo(7);\n                                })))\n                .willReturn(RESERVATION_IDENTIFIER);\n\n        // when\n        ResultActions resultActions = performRequest(getJsonRequestBody());\n\n        // then\n        resultActions\n                .andExpect(status().isCreated())\n                .andExpect(jsonPath(\"$.reservationIdentifier\").value(RESERVATION_IDENTIFIER.value()));\n    }\n}\n</code></pre> <p>In the test, <code>MockMvc</code> is used, which sets up Spring with only the beans related to the web layer, such as controllers,  controller advice, and filters. It does not start up a real web server; instead, it mocks request and response objects.  The main purpose of these tests is to verify your application's web layer configuration, not the internal behavior of  the Spring framework.</p> <p>How to test error handling?</p> <p>If an exception is thrown in controller logic (for example, during command autovalidation or built-in Spring  validation of a request), the solution is straightforward\u2014it should be tested with an integration test. However,  exceptions thrown within use case logic can be more challenging to handle. Typically, error handling is externalized from controllers using <code>ControllerAdvice</code> in Spring. There are two main  approaches:</p> <ol> <li>Write an integration test:     Because @WebMvcTest includes ControllerAdvice beans, you can write integration tests that cover error handling logic`     The advantage of this approach is that test execution is generally faster than a full module test. However,      the downside is that if the use case no longer throws the exception (e.g., the logic is removed), it is easy to forget to remove      the related test from the controller integration tests.</li> <li>Write a module test:     This approach has two main drawbacks: significantly longer execution time, and a potentially more complex      test setup. However, if the use case stops throwing the exception, the module test will fail, making it easier      to detect such changes and keep your tests up to date.</li> </ol>"},{"location":"pyramid/test_pyramid/","title":"Test Pyramid","text":""},{"location":"pyramid/test_pyramid/#composition-of-the-test-pyramid","title":"Composition of the Test Pyramid","text":"Test Pyramid by Chris Richardson, microservices.io <p>The test pyramid is a concept in software testing that illustrates the types of tests and the recommended proportion of each in a well-tested application. The lower you go in the pyramid, the faster and cheaper the tests become, so there should be more of them. As you move higher in the pyramid, the tests become slower, more expensive, and more brittle; there should therefore be fewer of these.</p> <p>The base of the pyramid consists of unit tests, which are fast, inexpensive to write, and stable. The majority of business logic should be covered by these tests. Unit tests give a short feedback loop, allowing developers to quickly identify and fix issues.</p> <p>The next layer are integration tests. These tests check how the application interacts with external systems such as databases, message brokers, or other services (contract tests). Integration tests are slower and more expensive to set up than unit tests.</p> <p>In the middle of the pyramid are component tests. These verify end-to-end use cases within the application, typically starting from incoming adapters, passing through business logic, and ending with outgoing adapters. Component tests are relatively slow, more expensive to write than integration tests, and more brittle. They mainly focus on validating happy paths.</p> <p>At the top of the pyramid are end-to-end tests. These assess the application from the reservationParticipant's perspective, making them very slow, costly to write, and highly brittle. End-to-end tests should be reserved for business-critical scenarios and executed only in production-like environments. They can be conducted via the user interface or the API. While UI-based tests closely mimic the reservationParticipant experience and can reveal problems missed by other types of tests, they are typically more brittle due to frequent UI changes.</p>"},{"location":"pyramid/test_pyramid/#why-is-the-test-pyramid-important","title":"Why is the Test Pyramid Important?","text":"<p>The test pyramid is critical because it enables teams to maximize the value and efficiency of their testing strategy. By following the pyramid\u2019s structure and maintaining the right proportion of test types, you gain several key benefits:</p> <ul> <li>Cost Efficiency: Automated tests, especially at the lower levels (unit and integration), are fast to execute and inexpensive to maintain, reducing the overall cost of quality assurance efforts.</li> <li>Higher Team Velocity: A strong foundation of fast and reliable tests provides rapid feedback, allowing the team to develop and release features more quickly and with greater confidence.</li> <li>Fewer Bugs in Production: Well-structured test coverage across all application layers helps catch issues early, reducing the likelihood of defects reaching users.</li> <li>Living Documentation: Tests can serve as precise documentation of expected application behavior and requirements, making the codebase easier to understand for current and future team members.</li> <li>Test Stability: By emphasizing lower-level tests, which tend to be more stable and less brittle, you minimize flaky test failures and maintenance overhead.</li> <li>Confidence in Refactoring: With comprehensive automated tests in place, engineers can refactor code more bravely, knowing regressions will be caught quickly.</li> </ul> <p>In contrast, imbalanced test suites\u2014often visualized by antipatterns like the test ice-cream cone\u2014lead to unstable, slow, and expensive testing. Adhering to the test pyramid helps teams build higher-quality software while keeping development efficient and sustainable.</p>"},{"location":"pyramid/test_pyramid/#references","title":"References","text":"<ul> <li>Microservices Patterns</li> <li>The Practical Test Pyramid</li> </ul>"},{"location":"unit/unit_tests/","title":"Unit tests","text":"<p>Unit tests form the foundation of the testing pyramid. They should constitute the majority of the tests in a project, as they are designed to be fast, stable, and inexpensive to run.</p> <p>The term \"unit\" itself is quite vague and can be misleading\u2014it doesn't refer solely to a single class or method, as is often assumed. A unit can be:</p> <ul> <li>A single class,</li> <li>A group of classes,</li> <li>A module,</li> <li>An aggregate (in the context of Domain-Driven Design, DDD).</li> </ul> <p>However, the size of the unit is a secondary consideration. What matters most are the characteristics of unit tests, as summarized by the F.I.R.S.T. principle from Robert C.\u00a0Martin's Clean Code book:</p> <ul> <li>Fast: Unit tests should execute quickly.</li> <li>Independent: They should not depend on each other; each test must be able to run in isolation.</li> <li>Repeatable: They should produce the same result every time they are run, regardless of the environment.</li> <li>Self-Validating: Tests should automatically determine whether they pass or fail, without requiring manual inspection\u2014fortunately, this is standard practice nowadays.</li> <li>Timely: Tests should be written before the production code they verify, a key principle of Test-Driven Development (TDD). Even if you don't practice TDD, tests should still be written within the same time frame as the code they validate. Writing tests should not be postponed or moved to a separate task or ticket.</li> </ul> <p>We can distinguish between two styles of unit tests: solitary and sociable, depending on how they handle the dependencies of the class under the test.</p>"},{"location":"unit/unit_tests/#solitary-unit-tests","title":"Solitary unit tests","text":"<pre><code>def \"Should create participant\"() {\n    given: \"Command of participant creation\"\n    def command = new CreateReservationParticipantUseCase.Command(FIRST_NAME, LAST_NAME)\n\n    this.participantFactory.create(command) &gt;&gt; new ReservationParticipant(new ReservationParticipantIdentifier(GENERATED_IDENTIFIER), FIRST_NAME, LAST_NAME)\n\n    when: \"Participant is created\"\n    def identifier = createParticipantUseCase.create(command)\n\n    then: \"Identifier is generated\"\n    identifier.value() == GENERATED_IDENTIFIER\n\n    and: \"Participant is inserted into repository\"\n    1 * insertParticipantPort.insert(_ as ReservationParticipant) &gt;&gt; { ReservationParticipant participant -&gt;\n        assert participant.identifier().value() == GENERATED_IDENTIFIER\n        assert participant.firstName() == FIRST_NAME\n        assert participant.surname() == LAST_NAME\n        return participant.identifier()\n    }\n}\n</code></pre> <p>Solitary unit tests\u2014also known as the mockist style - rely on mocking every dependency. The idea is to isolate the unit under test from its collaborators.</p> <p>Advantages:</p> <ul> <li>Isolation: It is sometimes easier to mock a dependency and treat it as a black box.</li> <li>Easy to create: Easy to create but not always. For some classes like mappers it is hard to mock it.</li> </ul> <p>Disadvantages:</p> <ul> <li>Maintenance overhead: Changing the code structure (e.g., refactoring) can break tests, increasing maintenance   efforts.</li> <li>Mismatch risk: The mocked behavior might differ from real behavior, potentially hiding integration issues.</li> <li>Test proliferation: More tests are needed\u2014often one per class\u2014to cover all behaviors.</li> <li>Mock not fit to every type of class: Mocking some classes like mappers does not make sense, as logic of mapping   would be repeated in tests.</li> </ul>"},{"location":"unit/unit_tests/#sociable-unit-tests","title":"Sociable unit tests","text":"<pre><code>def \"Should create participant\"() {\n    given: \"Command of participant creation\"\n    def command = new CreateReservationParticipantUseCase.Command(FIRST_NAME, LAST_NAME)\n\n    when: \"Participant is created\"\n    def identifier = createParticipantUseCase.create(command)\n\n    then: \"Identifier is generated\"\n    identifier.value() == GENERATED_IDENTIFIER\n\n    and: \"Participant is inserted into repository\"\n    def participantByIdentifier = participantInMemoryAdapter.findBy(identifier)\n    participantByIdentifier.isPresent()\n\n    def participant = participantByIdentifier.get()\n    participant.firstName() == FIRST_NAME\n    participant.surname() == LAST_NAME\n}\n</code></pre> <p>Sociable unit tests, sometimes referred to as the classicist style, do not rely on mocking dependencies. Instead, they use real implementations for components, or lightweight in-memory substitutes for external systems like databases. These tests are typically written against the public API of a module or a group of classes within a package.</p> <p>Advantages:</p> <ul> <li>Realism: Tests are more realistic as they use actual implementations, revealing issues that might only surface in   integrated environments.</li> <li>Robustness: Because they follow production-like interactions, changes in the internal code structure are less   likely to break the tests. Only changes in the public API will cause test failures. Every other change that does not   affect on a result of the method will not break the test.</li> <li>API-driven: Testing is centered around the public interface, which better reflects how the module is used.</li> <li>Reduced number of tests: Focusing on modules or groups of classes typically means fewer tests need to be   maintained.</li> <li>BDD: Tests can be written in a behavior-driven development (BDD) style, making them more readable and   understandable.</li> </ul> <p>Disadvantages:</p> <ul> <li>Complex setup: Dependencies might have their own dependencies, resulting in complex configuration for the test   environment.</li> <li>In-memory limitations: Creating in-memory implementations (for instance, for databases) can add overhead and may   not perfectly replicate real-world behavior. Also, any changes in real database adapters will be need to be reflected   in in-memory implementations.</li> </ul>"},{"location":"unit/unit_tests/#when-to-use-which-style","title":"When to use which style?","text":"<p>As is often said in IT, it depends. Due to its flexibility, sociable unit tests fit most scenarios. However, there are situations where solitary unit tests are more appropriate. In some cases, a mixed style can be employed\u2014some dependencies can be mocked while others use real implementations.</p> <p>A great talk by Sandro Mancuso on this topic is available here: Does TDD Really Lead to Good Design? (Sandro Mancuso).</p>"},{"location":"unit/unit_tests/#when-to-use-a-mock-and-when-to-use-a-real-implementation","title":"When to use a mock and when to use a real implementation?","text":"<p>Here are some questions to help you decide whether to mock a dependency or use a real implementation:</p> <ol> <li> <p>Does the dependency belong to the class under test?</p> <ul> <li>If yes, use the real implementation. For example, strategies in the Strategy pattern belong solely to their client   class, making mocking unnecessary.</li> <li>If not, mock it. Dependencies shared among multiple classes are better mocked. However, there are exceptions to   this rule, such as utility classes, which should have their own tests but also should not be mocked in the unit   under test.</li> </ul> </li> <li> <p>Is the dependency a Domain-Driven Design (DDD) aggregate?</p> <ul> <li>Aggregates typically shouldn\u2019t be mocked.</li> </ul> </li> <li> <p>Will mocking the dependency require replicating logic?</p> <ul> <li>For example, mocking mappers often involves replicating mapping logic in tests. In such cases, use a real   implementation. If a mapper is complex and depends on other services that require mocking, re-evaluate its design.   Ideally, mappers should remain simple.</li> </ul> </li> <li> <p>Does the dependency perform side effects?</p> <ul> <li>Database operations, REST API calls, or AMQP communication should not be part of unit tests; these are better   suited for integration tests. In unit tests, mocks can be used, but in-memory implementations should also be   considered. For example, database repositories can have their own in-memory test implementations instead of being   mocked. This approach can significantly simplify tests. For operations like \"fire and forget\" messaging, simple   mocks can be used without any negative impact.</li> </ul> </li> </ol>"},{"location":"unit/unit_tests/#one-test-one-behavior","title":"One Test, One Behavior","text":"<p>It is crucial that each test verifies exactly one behavior. This principle ensures that tests are focused, easy to understand, and maintainable. A single test that checks multiple behaviors can lead to confusion, make debugging harder, and increase maintenance efforts.</p> <p>The following test violates the principle by testing two behaviors at once:</p> <pre><code>def \"Should create user and send welcome email\"() {\n    given: \"Command of user creation\"\n    def command = new CreateUserUseCase.Command(FIRST_NAME, LAST_NAME, EMAIL)\n\n    and: \"Mock email service\"\n    emailService.sendWelcomeEmail(EMAIL) &gt;&gt; true\n\n    when: \"User is created\"\n    createUserUseCase.create(command)\n\n    then: \"User is created\"\n    1 * insertUserPort.insert(_ as User) &gt;&gt; { User user -&gt;\n        assert user.identifier().value() == GENERATED_IDENTIFIER\n        assert user.firstName() == FIRST_NAME\n        assert user.surname() == LAST_NAME\n        assert user.email() == EMAIL\n        return user.identifier()\n    }\n\n    and: \"Welcome email is sent\"\n    1 * emailService.sendWelcomeEmail(EMAIL)\n}\n</code></pre> <p>This test checks two behaviors: - User creation - Sending a welcome email</p> <p>These are two independent behaviors that can change for different reasons. Combining them into a single test makes it harder to identify the cause of a failure and increases maintenance complexity.</p>"},{"location":"unit/unit_tests/#why-is-this-important","title":"Why is This Important?","text":"<ol> <li>Clarity: Each test has a clear and singular purpose, making it easier to understand what is being verified.</li> <li>Debugging: When a test fails, it is immediately clear which behavior is broken, simplifying the debugging process.</li> <li>Maintainability: Focused tests are easier to update when the code changes, reducing the risk of unintended side effects.</li> </ol> <p>By adhering to the \"one test, one behavior\" rule, you ensure that your tests remain robust and readable.</p>"},{"location":"unit/unit_tests/#what-is-not-worth-to-unit-test","title":"What is not worth to unit test","text":"<ul> <li>Adapters for External Systems:   Components that interface with external services such as databases, HTTP APIs, or messaging systems should be tested   through integration tests. These tests validate the communication with the real system or a close substitute.</li> <li>Configuration Classes:   These classes usually contain no business logic. Integration often verifies their correctness or end-to-end   tests where the actual configuration is used.</li> <li>Simple Getters and Setters:   If these methods do nothing more than return or set a value, writing unit tests for them might not be worthwhile,   unless additional logic is present.</li> </ul>"},{"location":"unit/unit_tests/#references","title":"References","text":"<ul> <li>https://martinfowler.com/bliki/UnitTest.html</li> <li>Improving your Test Driven Development in 45 minutes - Jakub Nabrdalik</li> <li>Does TDD Really Lead to Good Design? (Sandro Mancuso)</li> <li>Clean Code: A Handbook of Agile Software Craftsmanship (Rober C.\u00a0Martin)</li> </ul>"}]}